{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Learn by Doing: ENSO Analysis\n",
    "\n",
    "Developed By: Dr. Kerrie Geil, Mississippi State University\n",
    "\n",
    "Date: April 2024\n",
    "\n",
    "Requirements: list space, RAM, and pacakge requirements\n",
    "\n",
    "Link: notebook available to download at "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Description </u>\n",
    "\n",
    "This notebook helps the learner build intermediate python programming skills through data query, manipulation, analysis, and visualization. Learning will be centered around the El Nino Southern Oscillation (ENSO) climate pattern and its effects on temperature and precipitation. The notebook is aimed at learners who already have some knowledge of programming and statistics. \n",
    "\n",
    "<u> Summary of Contents </u>\n",
    "\n",
    "put an outline of tasks/skills here\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to ENSO\n",
    "\n",
    "Put a description of what they are\n",
    "\n",
    "Include a bunch of links\n",
    "different ENSO indices https://climatedataguide.ucar.edu/climate-data/nino-sst-indices-nino-12-3-34-4-oni-and-tni\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Science Questions\n",
    "\n",
    "To pick up some useful intermediate python programming skills, this notebook will investigate the following ENSO-related science questions using simple statistics:\n",
    "\n",
    "1) How many strong El Nino and La Nina events occurred from 1948-2023? How many periods of neutral conditions?\n",
    "2) Using composite analysis, what pattern do we see in sea surface temperature during El Nino and La Nina conditions?\n",
    "3) During boreal winter (DJF), where do El Nino and La Nina conditions affect temperature and precipitation globally?\n",
    "4) Which areas of the United States experience statistically significant ENSO effects on winter (DJF) temperature and precipitation?\n",
    "5) \n",
    "\n",
    "**Disclaimer:** This notebook is intended for python programming learning. There are many datasets and statistical methods we could use to answer our science questions. The techniques used in this notebook are chosen for their simplicity since we are focused on learning intermediate programming skills as opposed to a focus on producing peer-review level analyses. You will undoubtedly see different techniques, thresholds, seasons, and more complex statisical methods used in ENSO literature. \n",
    "\n",
    "\n",
    "data description | frequency | units | dataset name | source\n",
    "---|---|---|---|---\n",
    "nino 3.4 sst index | monthly | C | Nino 3.4 SST index | [NOAA PSL](https://psl.noaa.gov/gcos_wgsp/Timeseries/Nino34/)\n",
    "sea surface temperature | monthly | C | HadISST1 | [UKMO Hadley Centre](https://www.metoffice.gov.uk/hadobs/hadisst/)\n",
    "average air temperature | monthly | C | BEST | [Berkeley Earth](https://berkeleyearth.org/data/)\n",
    "precipitation | monthly | mm/day | NOAA PREC/L | [NOAA PSL](https://psl.noaa.gov/data/gridded/data.precl.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Python Packages and Defining Your Workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the python packages we will need here\n",
    "\n",
    "import os\n",
    "# from urllib.request import urlretrieve\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "\n",
    "# import numpy.testing as npt\n",
    "# import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "\n",
    "# from collections import OrderedDict\n",
    "# import gzip\n",
    "# import shutil\n",
    "\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learners need to update these paths to reflect locations on their own computer/workspace\n",
    "\n",
    "# path to your working directory (where this notebook is on your computer)\n",
    "work_dir = r'C://Users/kerrie/Documents/01_LocalCode/repos/MSU_py_training/learn_by_doing/ENSO/' \n",
    "# work_dir = r'C://Users/kerrie.WIN/Documents/code/MSU_py_training/learn_by_doing/ENSO/' \n",
    "\n",
    "# path to where you'll download and store the data files\n",
    "data_dir = r'C://Users/kerrie/Documents/02_LocalData/tutorials/ENSO/'\n",
    "# data_dir=r'C://Users/kerrie.WIN/Documents/code/MSU_py_training/learn_by_doing/ENSO/'\n",
    "\n",
    "# path to write output files and figures\n",
    "output_dir = work_dir+'outputs/'\n",
    "\n",
    "# create directories if they don't exist already\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Obtaining the Data\n",
    "\n",
    "Scripted downloads of the datasets used here can be found in a separate notebook called [get_enso_datasets.ipynb](). If you haven't obtained the data already, use the get_enso_datasets notebook to download the Nino3.4 index, HadISST1 sea surface temperature, Berkeley Earth temperature, and GPCC precipitation data.\n",
    "\n",
    "# Data Pre-processing\n",
    "\n",
    "Set our 4 different datasets up with the same time dimension labels and calculate anomalies for SST, PR, and T using the same base period as the nino 3.4 index (1981-2010).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames\n",
    "nino_f = data_dir+'nino34_anomalies_monthly_NOAA.txt'\n",
    "# sst_f = data_dir+'sst_monthly_HadISST1_UKMO.nc'\n",
    "sst_f = data_dir+'sst_monthly_COBE2_JMA.nc'\n",
    "t_f = data_dir+'tavg_monthly_BerkeleyEarth.nc'\n",
    "\n",
    "pr_f = data_dir+'precip_monthly_PRECL_NOAA.nc'\n",
    "\n",
    "# subset years\n",
    "year_start = '1948'\n",
    "year_end = '2023'\n",
    "\n",
    "# base period years (for anomalies)\n",
    "base_start = '1981'\n",
    "base_end = '2010'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nino 3.4 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nino3.4 index data\n",
    "\n",
    "# our data file contains a row for each year of data and each column is one of 12 monthly anomaly values for the Nino 3.4 area \n",
    "# the base period for the anomalies is 1981-2010\n",
    "\n",
    "# there are plenty of ways to load txt data, we'll use pandas\n",
    "nino_raw=pd.read_csv(nino_f,sep='\\s+',skiprows=1,skipfooter=7,header=None,index_col=0,na_values=-99.99,engine='python')\n",
    "# nino_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse the data into a 1D array timeseries\n",
    "nino=nino_raw.to_numpy().flatten()\n",
    "\n",
    "# len(nino),nino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datetimes\n",
    "dates=pd.date_range('1870-01-01','2024-12-01',freq='MS')\n",
    "\n",
    "# len(dates),dates[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an xarray object with metadata labels attached (time)\n",
    "nino=xr.DataArray(nino,dims='time',coords={'time':dates})\n",
    "\n",
    "# assign some variable attributes\n",
    "nino.attrs['standard_name']='nino3.4 index'\n",
    "nino.attrs['units']='C'\n",
    "# nino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset in time using time labels\n",
    "nino=nino.sel(time=slice(year_start,year_end))\n",
    "# nino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "fig=plt.figure(figsize=(15,2))\n",
    "nino.plot()\n",
    "plt.title(\"Nino 3.4 Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sea Surface Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "ds=xr.open_dataset(sst_f)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull variable from xr dataset\n",
    "sst=ds.sst\n",
    "# sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset in time\n",
    "\n",
    "# first assign new time values that will match nino (month start not center of months)\n",
    "# dates=pd.date_range('1870-01-01','2024-02-01',freq='MS')\n",
    "# sst['time']=dates\n",
    "\n",
    "# now subset in time\n",
    "sst=sst.sel(time=slice(year_start,year_end))\n",
    "# sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate anomalies\n",
    "\n",
    "# first calculate the monthly climatological values over the base period\n",
    "sst_base=sst.sel(time=slice(base_start,base_end))\n",
    "sst_clim=sst_base.groupby(sst_base.time.dt.month).mean('time')\n",
    "# sst_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate the anomalies\n",
    "sst_anom=sst.groupby(sst.time.dt.month) - sst_clim\n",
    "\n",
    "# assign some variable attributes\n",
    "sst_anom.attrs['standard_name']='sst anomaly'\n",
    "sst_anom.attrs['units']='C'\n",
    "# sst_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "ptime='2020-01'\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "sst_anom.sel(time=ptime).plot()\n",
    "plt.title('SST anomalies '+ptime)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset(pr_f)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull variable from xr dataset\n",
    "pr=ds.precip\n",
    "\n",
    "# this data's times already match nino's so we don't need to re-assign the coordinate labels\n",
    "# just subset\n",
    "pr=pr.sel(time=slice(year_start,year_end))\n",
    "\n",
    "# calculate anomalies\n",
    "pr_base=pr.sel(time=slice(base_start,base_end))\n",
    "pr_clim=pr_base.groupby(pr_base.time.dt.month).mean('time')\n",
    "pr_anom=pr.groupby(pr.time.dt.month) - pr_clim\n",
    "\n",
    "# assign some variables attributes\n",
    "pr_anom.attrs['standard_name']='pr anomaly'\n",
    "pr_anom.attrs['units']='mm/day'\n",
    "\n",
    "# pr_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "pr_anom.sel(time=ptime).plot()\n",
    "plt.title('PR anomalies '+ptime)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset(t_f)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these dates are whacky so we'll replace with datetimes to match the other datasets\n",
    "dates=pd.date_range('1750-01-01','2024-03-01',freq='MS')\n",
    "ds['time']=dates\n",
    "\n",
    "# we also need to rename the dimension 'month_number' for groupby to work correctly\n",
    "# and so we don't trip up later we'll rename latitude longitude to lat and lon like the other datasets\n",
    "ds=ds.rename({'month_number':'month','latitude':'lat','longitude':'lon'})\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change base period\n",
    "# this data is provided as anomalies using the base period 1951-1980\n",
    "# we need to change the base period to match the rest of our data anomalies\n",
    "\n",
    "# pull variables from xr dataset\n",
    "t_anom_5180=ds.temperature\n",
    "clim_5180=ds.climatology\n",
    "\n",
    "# create temperature values working backward with anomalies plus climatology\n",
    "t=t_anom_5180.groupby(t_anom_5180.time.dt.month)+clim_5180\n",
    "\n",
    "# new base period climatological values\n",
    "t_base=t.sel(time=slice(base_start,base_end))\n",
    "clim_8110 = t_base.groupby(t_base.time.dt.month).mean('time')\n",
    "\n",
    "# anomalies with new base period\n",
    "t_anom=t.groupby(t.time.dt.month)-clim_8110\n",
    "\n",
    "# subset in time\n",
    "t_anom=t_anom.sel(time=slice(year_start,year_end))\n",
    "\n",
    "# assign some variable attributes\n",
    "t_anom.attrs['standard_name']='T anomaly'\n",
    "t_anom.attrs['units']='C'\n",
    "\n",
    "# t_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "ptime='2020-01'\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "t_anom.sel(time=ptime).plot()\n",
    "plt.title('T anomalies '+ptime)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to start our analysis with the variables nino, sst_anom, pr_anom, and t_anom. If you are used to seeing a list of variables you've made (like in Matlab or RStudio) that is available for python/Jupyter through the IDE you use (like VS Code, Spyder, Pycharm, etc). There is usually a console option that you can open to see all the variables you've made is point. This is useful for seeing variable shapes and data types as well as seeing which variables you could potentially delete if you suspect you'll be memory limited during your analysis.\n",
    "\n",
    "Let's double check our 4 variable shapes below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nino.shape, sst_anom.shape, pr_anom.shape, t_anom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ds,nino_raw,pr,pr_base,pr_clim,sst,sst_base,sst_clim,t,t_anom_5180,t_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) How many strong El Nino and La Nina events have occurred from 1948 to 2023?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer to this question of course depends on the definition of a strong ENSO event.\n",
    "\n",
    "There are multiple methods for identifying ENSO and strong ENSO events but we will use the following criteria:\n",
    "- Input data: Nino 3.4 Index 5-month centered running mean\n",
    "- Criteria: 5 consecutive months exceeding the threshold value\n",
    "- Threshold: +/- 0.7 C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants based on our criteria\n",
    "nmonths=5\n",
    "event_thresh=0.7\n",
    "neutral_thresh=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first calculate the rolling mean\n",
    "nino_rollmean=nino.rolling(time=nmonths,center=True).mean()\n",
    "\n",
    "# plot it\n",
    "fig=plt.figure(figsize=(15,2))\n",
    "plt.axhline(y=-event_thresh,color='purple',linestyle='dashed',linewidth=0.5)\n",
    "plt.axhline(y=0,color='grey',linestyle='dashed',linewidth=0.5)\n",
    "plt.axhline(y=event_thresh,color='purple',linestyle='dashed',linewidth=0.5)\n",
    "nino_rollmean.plot()\n",
    "plt.title(\"Nino 3.4 Index 5-mo Rolling Mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anywhere the nino3.4 rolling mean (blue line) exceeds the thresholds (purple lines) is potentially an ENSO event. To identify which peaks and valleys in the timeseries qualify as ENSO events we need to identify where the thresholds are exceeded for at least 5 consecutive months.  \n",
    "\n",
    "We'll use a for loop to identify ENSO events in the timeseries and mark months during an El Nino event with +1 and months during a La Nina event with -1. \n",
    "\n",
    "We'll also use the criteria of 5 consecutive months under a threshold of +/-0.2C to identify neutral conditions and mark these months with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array to hold our results and initialize to nan\n",
    "# this array is where we will fill values with +1,-1, or 0\n",
    "nino_events=nino_rollmean.copy() \n",
    "nino_events[:]=np.nan\n",
    "\n",
    "# look at the first 4 values\n",
    "nino_events[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through months and fill +1, -1, or 0 for windows of 5 months that meet our criteria\n",
    "\n",
    "for i,value in enumerate(nino_rollmean):\n",
    "    # La Nina conditions\n",
    "    if  value < -event_thresh:\n",
    "        # possible La Nina conditions, look forward 4 more months\n",
    "        window=nino_rollmean[i:i+nmonths]\n",
    "        if all(window < -event_thresh):\n",
    "            nino_events[i:i+nmonths]=-1\n",
    "\n",
    "    # El Nino conditions\n",
    "    if  value > event_thresh:\n",
    "        # possible El Nino conditions, look forward 4 more months\n",
    "        window=nino_rollmean[i:i+nmonths]\n",
    "        if all(window > event_thresh):\n",
    "            nino_events[i:i+nmonths]=1     \n",
    "    \n",
    "    # neutral conditions    \n",
    "    if (-neutral_thresh < value < neutral_thresh):\n",
    "        # possible neutral conditions, look forward 4 more months\n",
    "        window=nino_rollmean[i:i+nmonths]\n",
    "        if all(-neutral_thresh < window) & all(window < neutral_thresh):\n",
    "            nino_events[i:i+nmonths]=0  \n",
    "\n",
    "            \n",
    "# plot it\n",
    "fig=plt.figure(figsize=(15,2))\n",
    "plt.axhline(y=0,color='grey',linestyle='dashed',linewidth=0.5)\n",
    "nino_events.plot(linestyle='None',marker='o',markersize=1)\n",
    "plt.title(\"periods with El Nino, La Nina, or neutral conditions\")\n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the nino_events array to add shading to the nino_rollmean plot as well as count how many el nino and la nina events there are in the timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we'll get the timing of the start and end of each event\n",
    "\n",
    "# el nino\n",
    "nino_bounds=[] # empty list to hold the results\n",
    "istart=0\n",
    "iend=0\n",
    "start_flag=False\n",
    "\n",
    "for i,val in enumerate(nino_events[:-1]):    \n",
    "    # find each nino start\n",
    "    if (val==1) and (start_flag==False):\n",
    "        istart=i\n",
    "        start_flag=True\n",
    "    # find each nino end and save start/end times to a list\n",
    "    if (start_flag) and (iend==0) and (nino_events[i+1]!=1):\n",
    "        iend=i\n",
    "        # append a tuple (event start time, event end time) to our list of results\n",
    "        nino_bounds.append((nino_events.time[istart].data,nino_events.time[iend].data))\n",
    "        # reset values so we can look for the next event\n",
    "        start_flag=False\n",
    "        iend=0\n",
    "\n",
    "len(nino_bounds),nino_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la nina\n",
    "nina_bounds=[] # empty list to hold the results\n",
    "istart=0\n",
    "iend=0\n",
    "start_flag=False\n",
    "\n",
    "for i,val in enumerate(nino_events[:-1]):    \n",
    "    # find each nina start\n",
    "    if (val==-1) and (start_flag==False):\n",
    "        istart=i\n",
    "        start_flag=True\n",
    "    # find each nina end and save start/end times to a list\n",
    "    if (start_flag) and (iend==0) and (nino_events[i+1]!=-1):\n",
    "        iend=i\n",
    "        # append a tuple (event start time, event end time) to our list of results\n",
    "        nina_bounds.append((nino_events.time[istart].data,nino_events.time[iend].data))\n",
    "        # reset values so we can look for the next event        \n",
    "        start_flag=False\n",
    "        iend=0 \n",
    "\n",
    "# neutral\n",
    "neutral_bounds=[] # empty list to hold the results\n",
    "istart=0\n",
    "iend=0\n",
    "start_flag=False\n",
    "\n",
    "for i,val in enumerate(nino_events[:-1]):    \n",
    "    # find each neutral start\n",
    "    if (val==0) and (start_flag==False):\n",
    "        istart=i\n",
    "        start_flag=True\n",
    "    # find each neutral end and save start/end times to a list\n",
    "    if (start_flag) and (iend==0) and (nino_events[i+1]!=0):\n",
    "        iend=i\n",
    "        # append a tuple (start time, end time) to our list of results\n",
    "        neutral_bounds.append((nino_events.time[istart].data,nino_events.time[iend].data))\n",
    "        # reset values so we can look for the next neutral period        \n",
    "        start_flag=False\n",
    "        iend=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 3 lists (nino_bounds, nina_bounds, neutral_bounds) containing tuples of the start and end datetime for each event. \n",
    "\n",
    "The length of each list will tell us how many el nino, la nina, and neutral events we found in the time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('How many strong el nino and la nina events occurred from 1948 to 2023?')\n",
    "print(len(nino_bounds),'strong el nino events')\n",
    "print(len(nina_bounds),'strong la nina events') \n",
    "\n",
    "print(f'(and {len(neutral_bounds)} periods of neutral conditions)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the Nino 3.4 rolling mean with shading during el nino, la nina, and neutral conditions\n",
    "\n",
    "fig=plt.figure(figsize=(15,2))\n",
    "\n",
    "# horizontal guide lines\n",
    "plt.axhline(y=-event_thresh,color='purple',linestyle='dashed',linewidth=0.5)\n",
    "plt.axhline(y=0,color='grey',linestyle='dashed',linewidth=0.5)\n",
    "plt.axhline(y=event_thresh,color='purple',linestyle='dashed',linewidth=0.5)\n",
    "\n",
    "# plot the rolling mean timeseries with title\n",
    "nino_rollmean.plot()\n",
    "plt.title(\"Nino 3.4 Index 5-mo Rolling Mean with shading for nino/nina/neutral conditions\")\n",
    "\n",
    "# add blue shading during nino events\n",
    "for tstart,tend in nino_bounds:\n",
    "    plt.axvspan(tstart,tend, color='cyan', alpha=0.25, lw=0)\n",
    "\n",
    "# add yellow shading during nina events    \n",
    "for tstart,tend in nina_bounds:\n",
    "    plt.axvspan(tstart,tend, color='gold', alpha=0.25, lw=0)\n",
    "\n",
    "# add grey shading during neutral periods    \n",
    "for tstart,tend in neutral_bounds:\n",
    "    plt.axvspan(tstart,tend, color='grey', alpha=0.25, lw=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Using composite analysis, what pattern do we see in sea surface temperature during El Nino and La Nina conditions?\n",
    "\n",
    "remember, our array of sea surface temperature anomalies is called **sst_anom**\n",
    "\n",
    "and we've identified periods with el nino, la nina, or neutral conditions in the array called **nino_events**\n",
    "\n",
    "A composite is just the time-mean of a group of sst anomaly maps for different months. In this case we'll have one group of sst anomalies for months with el nino conditions and another group of sst anomalies for months with la nina conditions. \n",
    "\n",
    "We'll also check what a composite of sst anomalies during neutral conditions looks like. We shouldn't see the strong spatial patterns during neutral conditions that we see during el nino or la nina conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make the el nino composite\n",
    "\n",
    "# keep sst anomalies only for months during el nino events\n",
    "# then take the average in time\n",
    "sst_nino=sst_anom.where(nino_events==1).mean('time',keep_attrs=True)\n",
    "\n",
    "# plot it\n",
    "sst_nino.plot(vmin=-2.,vmax=2.,cmap='RdBu_r')\n",
    "plt.title('mean sst anomalies during strong el nino events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the la nina composite\n",
    "\n",
    "# keep sst anomalies only for months during la nina events\n",
    "# then take the average in time\n",
    "sst_nina=sst_anom.where(nino_events==-1).mean('time',keep_attrs=True)\n",
    "\n",
    "# plot it\n",
    "sst_nina.plot(vmin=-2.,vmax=2.,cmap='RdBu_r')\n",
    "plt.title('mean sst anomalies during strong la nina events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now a composite for neutral conditions\n",
    "\n",
    "# keep sst anomalies only for months during neutral conditions\n",
    "# then take the average in time\n",
    "sst_neutral=sst_anom.where(nino_events==0).mean('time',keep_attrs=True)\n",
    "\n",
    "# plot it\n",
    "sst_neutral.plot(vmin=-2.,vmax=2.,cmap='RdBu_r')\n",
    "plt.title('mean sst anomalies during neutral periods')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) During boreal winter (DJF), where do El Nino and La Nina conditions affect temperature and precipitation globally?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get temperature anomalies only for times during el nino condition\n",
    "t_nino=t_anom.where(nino_events==1,drop=True)\n",
    "\n",
    "# now get only the winter months during el nino conditions and average months together\n",
    "t_nino_DJF=t_nino.groupby(t_nino.time.dt.season)['DJF'].mean('time',keep_attrs=True)\n",
    "\n",
    "# do the exact same thing for precipitation\n",
    "pr_nino=pr_anom.where(nino_events==1,drop=True)\n",
    "pr_nino_DJF=pr_nino.groupby(pr_nino.time.dt.season)['DJF'].mean('time',keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "\n",
    "fig,axes=plt.subplots(ncols=2,figsize=(12, 4))\n",
    "\n",
    "t_nino_DJF.plot(ax=axes[0],cmap='RdBu_r')\n",
    "axes[0].set_title('winter mean temperature anomalies\\n during El Nino conditions')\n",
    "\n",
    "pr_nino_DJF.plot(ax=axes[1],cmap='RdBu')\n",
    "axes[1].set_title('winter mean precipitation anomalies\\n during El Nino conditions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where are the above affects statistically significant?\n",
    "\n",
    "use a t test for difference in means between two groups of data: anomalies during el nino winter months and anomalies during neutral winter months\n",
    "\n",
    "(we could also test nino winter months vs all winter months and get very similar results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we'll create separate data samples to apply the statistical testing to\n",
    "\n",
    "# same first step as above except this time we're not taking the mean in time\n",
    "t_ninoDJF_group=t_nino.groupby(t_nino.time.dt.season)['DJF']  # t anomalies during el nino winters\n",
    "pr_ninoDJF_group=pr_nino.groupby(pr_nino.time.dt.season)['DJF']  # pr anomalies during el nino winters\n",
    "\n",
    "# now do the same for the neutral DJFs\n",
    "t_nuet=t_anom.where(nino_events==0,drop=True) # t anomalies during all months with neutral conditions\n",
    "t_neutDJF_group=t_nuet.groupby(t_nuet.time.dt.season)['DJF']  # t anomalies during neutral winters\n",
    "\n",
    "pr_nuet=pr_anom.where(nino_events==0,drop=True)  # pr anomalies during all months with neutral conditions\n",
    "pr_neutDJF_group=pr_nuet.groupby(t_nuet.time.dt.season)['DJF']  # pr anomalies during neutral winters\n",
    "\n",
    "\n",
    "print('t data sample sizes:',t_ninoDJF_group.shape, t_neutDJF_group.shape) \n",
    "print('pr data sample sizes:',pr_ninoDJF_group.shape, pr_neutDJF_group.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the statistical test using the scipy.stats package\n",
    "t_ttest=ss.ttest_ind(t_ninoDJF_group,t_neutDJF_group,axis=0)\n",
    "\n",
    "# ss.ttest_ind returns an object with multiple numpy arrays attached as attributes\n",
    "# you access them with .statistic, .pvalue, and .df\n",
    "t_ttest.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ease of plotting, we'll turn those numpy array results back into xarray data arrays\n",
    "# which basically means we're adding the lat and lon metadata back\n",
    "\n",
    "t_tstat=xr.DataArray(t_ttest.statistic, coords={'lat':('lat',t_nino.coords['lat'].data),'lon':('lon',t_nino.coords['lon'].data)})\n",
    "t_pval=xr.DataArray(t_ttest.pvalue, coords={'lat':('lat',t_nino.coords['lat'].data),'lon':('lon',t_nino.coords['lon'].data)})  \n",
    "t_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the statistical test using the scipy.stats package\n",
    "pr_ttest=ss.ttest_ind(pr_ninoDJF_group,pr_neutDJF_group)\n",
    "\n",
    "# for ease of plotting, we'll turn those numpy array results back into xarray data arrays\n",
    "# which basically means we're adding the lat and lon metadata back\n",
    "\n",
    "pr_tstat=xr.DataArray(pr_ttest.statistic, coords={'lat':('lat',pr_nino.coords['lat'].data),'lon':('lon',pr_nino.coords['lon'].data)})\n",
    "pr_pval=xr.DataArray(pr_ttest.pvalue, coords={'lat':('lat',pr_nino.coords['lat'].data),'lon':('lon',pr_nino.coords['lon'].data)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the same plot as above but only show the results where pval < 0.1\n",
    "pval=0.1\n",
    "\n",
    "fig,axes=plt.subplots(ncols=2,figsize=(12, 4))\n",
    "\n",
    "t_nino_DJF.where(t_pval<pval).plot(ax=axes[0],cmap='RdBu_r')\n",
    "axes[0].set_title('winter mean temperature anomalies\\n during El Nino conditions')\n",
    "\n",
    "pr_nino_DJF.where(pr_pval<pval).plot(ax=axes[1],cmap='RdBu')\n",
    "axes[1].set_title('winter mean precipitation anomalies\\n during El Nino conditions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ci_low=xr.DataArray(t_ttest.confidence_interval(confidence_level=0.90).low, coords={'lat':('lat',t_nino.coords['lat'].data),'lon':('lon',t_nino.coords['lon'].data)})\n",
    "t_ci_hi=xr.DataArray(t_ttest.confidence_interval(confidence_level=0.90).high, coords={'lat':('lat',t_nino.coords['lat'].data),'lon':('lon',t_nino.coords['lon'].data)})\n",
    "pr_ci_low=xr.DataArray(pr_ttest.confidence_interval(confidence_level=0.90).low, coords={'lat':('lat',pr_nino.coords['lat'].data),'lon':('lon',pr_nino.coords['lon'].data)})\n",
    "pr_ci_hi=xr.DataArray(pr_ttest.confidence_interval(confidence_level=0.90).high, coords={'lat':('lat',pr_nino.coords['lat'].data),'lon':('lon',pr_nino.coords['lon'].data)})\n",
    "\n",
    "fig,axes=plt.subplots(ncols=2,figsize=(12, 4))\n",
    "t_nino_DJF.where((t_ci_low > t_tstat)|(t_tstat > t_ci_hi)).plot(ax=axes[0],cmap='RdBu_r')\n",
    "axes[0].set_title('winter mean temperature anomalies\\n during El Nino conditions')\n",
    "\n",
    "pr_nino_DJF.where((pr_ci_low > pr_tstat)|(pr_tstat > pr_ci_hi)).plot(ax=axes[1],cmap='RdBu_r')\n",
    "axes[1].set_title('winter mean precipitation anomalies\\n during El Nino conditions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Which areas of the United States experience statistically significant ENSO impacts on temperature and precipitation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# pr_nino=pr_anom.where(nino_events==1).mean('time')\n",
    "# pr_nino.plot(cmap='RdBu')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr_nina=pr_anom.where(nino_events==-1).mean('time')\n",
    "# pr_nina.plot(cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr_neutral=pr_anom.where(nino_events==0).mean('time')\n",
    "# pr_neutral.plot(vmin=-3.5,vmax=3.5,cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr_nino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr_nino_conus=pr_nino.sel(lat=slice(51,23),lon=slice(230,300))\n",
    "\n",
    "# fig=plt.figure(figsize=(10,8))\n",
    "# ax=fig.add_subplot(111,projection=ccrs.PlateCarree())\n",
    "# ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "# ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "# ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "# cbar_kwargs={'shrink':0.5}\n",
    "# pr_nino_conus.plot(ax=ax,transform=ccrs.PlateCarree(),cbar_kwargs=cbar_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_anom_conus=pr_anom.sel(lat=slice(51,23),lon=slice(225,300))\n",
    "\n",
    "pr_nino_conus=pr_anom_conus.where(nino_events==1,drop=True)\n",
    "pr_ninoDJF_conus=pr_nino_conus.groupby(pr_nino_conus.time.dt.season)['DJF']\n",
    "\n",
    "pr_ninoDJF_conus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_anom_conus=t_anom.sel(lat=slice(23,51),lon=slice(-135,-60))\n",
    "\n",
    "t_nino_conus=t_anom_conus.where(nino_events==1,drop=True)\n",
    "t_ninoDJF_conus=t_nino_conus.groupby(t_nino_conus.time.dt.season)['DJF']\n",
    "\n",
    "t_ninoDJF_conus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutral conditions\n",
    "t_neut_conus=t_anom_conus.where(nino_events==0,drop=True)\n",
    "t_neutDJF_conus=t_neut_conus.groupby(t_neut_conus.time.dt.season)['DJF']\n",
    "\n",
    "pr_neut_conus=pr_anom_conus.where(nino_events==0,drop=True)\n",
    "pr_neutDJF_conus=pr_neut_conus.groupby(pr_neut_conus.time.dt.season)['DJF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,5))\n",
    "titles=['mean DJF t anomalies during el nino','mean DJF pr anomalies during el nino']\n",
    "\n",
    "for i,data in enumerate([t_ninoDJF_conus,pr_ninoDJF_conus]):\n",
    "\n",
    "    ax=fig.add_subplot(1,2,i+1,projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "    ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "    ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "    cbar_kwargs={'shrink':0.6}\n",
    "    data.mean('time',keep_attrs=True).plot(cmap='RdBu',cbar_kwargs=cbar_kwargs)#vmin=-7.5,vmax=7.5,cmap='RdBu')\n",
    "    plt.title(titles[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,5))\n",
    "titles=['mean DJF t anomalies during el nino','mean DJF p anomalies during el nino']\n",
    "nino_data=[t_ninoDJF_conus,pr_ninoDJF_conus]\n",
    "neutral_data=[t_neutDJF_conus,pr_neutDJF_conus]\n",
    "\n",
    "for i,data_tuple in enumerate(zip(nino_data,neutral_data)):\n",
    "    ttest=ss.ttest_ind(data_tuple[0],data_tuple[1])\n",
    "    # pr_tstat=xr.DataArray(pr_ttest.statistic, coords={'lat':('lat',pr_nino.coords['lat'].data),'lon':('lon',pr_nino.coords['lon'].data)})\n",
    "    pval=xr.DataArray(ttest.pvalue, coords={'lat':('lat',data_tuple[0].coords['lat'].data),'lon':('lon',data_tuple[0].coords['lon'].data)})     \n",
    "\n",
    "    ax=fig.add_subplot(1,2,i+1,projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "    ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "    ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "    cbar_kwargs={'shrink':0.6}\n",
    "    data_tuple[0].mean('time',keep_attrs=True).where(pval<0.05).plot(cmap='RdBu',cbar_kwargs=cbar_kwargs)#vmin=-7.5,vmax=7.5,cmap='RdBu')\n",
    "    plt.title(titles[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,5))\n",
    "titles=['mean DJF t anomalies during el nino','mean DJF p anomalies during el nino']\n",
    "nino_data=[t_ninoDJF_conus,pr_ninoDJF_conus]\n",
    "neutral_data=[t_neutDJF_conus,pr_neutDJF_conus]\n",
    "\n",
    "for i,data_tuple in enumerate(zip(nino_data,neutral_data)):\n",
    "    ttest=ss.ttest_ind(data_tuple[0],data_tuple[1])\n",
    "    tstat=xr.DataArray(ttest.statistic, coords={'lat':('lat',data_tuple[0].coords['lat'].data),'lon':('lon',data_tuple[0].coords['lon'].data)})\n",
    "    ci_low=xr.DataArray(ttest.confidence_interval(confidence_level=0.80).low, coords={'lat':('lat',data_tuple[0].coords['lat'].data),'lon':('lon',data_tuple[0].coords['lon'].data)})\n",
    "    ci_hi=xr.DataArray(ttest.confidence_interval(confidence_level=0.80).high, coords={'lat':('lat',data_tuple[0].coords['lat'].data),'lon':('lon',data_tuple[0].coords['lon'].data)})   \n",
    "\n",
    "    ax=fig.add_subplot(1,2,i+1,projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "    ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "    ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "    cbar_kwargs={'shrink':0.6}\n",
    "    data_tuple[0].mean('time',keep_attrs=True).where((tstat<ci_low)|(tstat>ci_hi)).plot(cmap='RdBu',cbar_kwargs=cbar_kwargs)#vmin=-7.5,vmax=7.5,cmap='RdBu')\n",
    "    plt.title(titles[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(15,6))\n",
    "# ax=fig.add_subplot(1,2,1,projection=ccrs.PlateCarree())\n",
    "fig,axes=plt.subplots(ncols=2, figsize=(12, 4), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "# axes[0].add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "# axes[0].add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "# axes[0].add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "# cbar_kwargs={'shrink':0.8}\n",
    "t_ninoDJF_conus.mean('time',keep_attrs=True).plot(ax=axes[0],cmap='RdBu')#,cbar_kwargs=cbar_kwargs)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,6))\n",
    "\n",
    "for i,(season,data) in enumerate(pr_nino_subset.groupby(pr_nino_subset.time.dt.season)):\n",
    "    season_composite=data.mean('time')\n",
    "\n",
    "    # fig.add_subplot(2,2,i+1)\n",
    "    ax=fig.add_subplot(2,2,i+1,projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "    ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "    ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "    cbar_kwargs={'shrink':0.8}\n",
    "    season_composite.plot(vmin=-1.6,vmax=1.6,cmap='RdBu',cbar_kwargs=cbar_kwargs)#vmin=-7.5,vmax=7.5,cmap='RdBu')\n",
    "    plt.title(season)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_nina_subset=pr_anom_conus.where(nino_events==-1,drop=True)\n",
    "for season,data in pr_nina_subset.groupby(pr_nina_subset.time.dt.season):\n",
    "    print(season,data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,6))\n",
    "\n",
    "for i,(season,data) in enumerate(pr_nina_subset.groupby(pr_nina_subset.time.dt.season)):\n",
    "    season_composite=data.mean('time')\n",
    "\n",
    "    ax=fig.add_subplot(2,2,i+1,projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "    ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "    ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "    cbar_kwargs={'shrink':0.8}\n",
    "    season_composite.plot(vmin=-1.6,vmax=1.6,cmap='RdBu',cbar_kwargs=cbar_kwargs)#vmin=-7.5,vmax=7.5,cmap='RdBu')\n",
    "    plt.title(season)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_neutral_subset=pr_anom_conus.where(nino_events==0,drop=True)\n",
    "for season,data in pr_neutral_subset.groupby(pr_neutral_subset.time.dt.season):\n",
    "    print(season,data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,8))\n",
    "\n",
    "for i,(season,data) in enumerate(pr_neutral_subset.groupby(pr_neutral_subset.time.dt.season)):\n",
    "    season_composite=data.mean('time')\n",
    "\n",
    "    ax=fig.add_subplot(2,2,i+1,projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "    ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "    ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "    cbar_kwargs={'shrink':0.6}\n",
    "    season_composite.plot(vmin=-1.6,vmax=1.6,cmap='RdBu',cbar_kwargs=cbar_kwargs)#vmin=-7.5,vmax=7.5,cmap='RdBu')\n",
    "    plt.title(season)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_nino_grouped=pr_nino_subset.groupby(pr_nino_subset.time.dt.season)\n",
    "pr_neutral_grouped=pr_neutral_subset.groupby(pr_neutral_subset.time.dt.season)\n",
    "# pr_neutral_grouped=pr_anom_conus.groupby(pr_anom_conus.time.dt.season)\n",
    "\n",
    "pval=0.1\n",
    "\n",
    "for ((label1,nino_data),(label2,neutral_data)) in zip(pr_nino_grouped,pr_neutral_grouped):\n",
    "    # print(label1,label2)\n",
    "    tstat=ss.ttest_ind(nino_data,neutral_data)\n",
    "    t=xr.DataArray(tstat.statistic, coords={'lat':('lat',nino_data.coords['lat'].data),'lon':('lon',nino_data.coords['lon'].data)})\n",
    "    p=xr.DataArray(tstat.pvalue, coords={'lat':('lat',nino_data.coords['lat'].data),'lon':('lon',nino_data.coords['lon'].data)})    \n",
    "\n",
    "    pr_plot=nino_data.mean('time')\n",
    "\n",
    "\n",
    "    fig=plt.figure(figsize=(8,3))\n",
    "    ax=fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "    ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "    ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "    cbar_kwargs={'shrink':0.6}\n",
    "    pr_plot.where(p<pval).plot(ax=ax,cmap='RdBu',cbar_kwargs=cbar_kwargs)\n",
    "    plt.title(label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_nino_grouped=pr_nino_subset.groupby(pr_nino_subset.time.dt.season)['DJF']\n",
    "pr_neutral_grouped=pr_neutral_subset.groupby(pr_neutral_subset.time.dt.season)['DJF']\n",
    "\n",
    "\n",
    "\n",
    "tstat=ss.ttest_ind(pr_nino_grouped,pr_neutral_grouped,equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr_nino_grouped.coords['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tstat.statistic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=xr.DataArray(tstat.statistic, coords={'lat':('lat',pr_nino_grouped.coords['lat'].data),'lon':('lon',pr_nino_grouped.coords['lon'].data)})\n",
    "p=xr.DataArray(tstat.pvalue, coords={'lat':('lat',pr_nino_grouped.coords['lat'].data),'lon':('lon',pr_nino_grouped.coords['lon'].data)})\n",
    "df=xr.DataArray(tstat.df, coords={'lat':('lat',pr_nino_grouped.coords['lat'].data),'lon':('lon',pr_nino_grouped.coords['lon'].data)})\n",
    "# ci=xr.DataArray(tstat.confidence_interval, coords={'lat':('lat',pr_nino_grouped.coords['lat'].data),'lon':('lon',pr_nino_grouped.coords['lon'].data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ci_low=xr.DataArray(tstat.confidence_interval(confidence_level=0.95).low, coords={'lat':('lat',pr_nino_grouped.coords['lat'].data),'lon':('lon',pr_nino_grouped.coords['lon'].data)})\n",
    "# ci_hi=xr.DataArray(tstat.confidence_interval(confidence_level=0.95).high, coords={'lat':('lat',pr_nino_grouped.coords['lat'].data),'lon':('lon',pr_nino_grouped.coords['lon'].data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.where((t<ci_low)|(t>ci_hi)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_nino_grouped=pr_nino_subset.groupby(pr_nino_subset.time.dt.season)['DJF']\n",
    "pr_anom_grouped=pr_anom_conus.groupby(pr_anom_conus.time.dt.season)['DJF']\n",
    "\n",
    "pr_nino_grouped.shape, pr_anom_grouped.shape\n",
    "# for  in enumerate(pr_neutral_subset.groupby(pr_neutral_subset.time.dt.season)):\n",
    "#     season_composite=data.mean('time')\n",
    "\n",
    "tstat2=ss.ttest_ind(pr_nino_grouped,pr_anom_grouped,equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=xr.DataArray(tstat2.statistic, coords={'lat':('lat',pr_nino_grouped.coords['lat'].data),'lon':('lon',pr_nino_grouped.coords['lon'].data)})\n",
    "p2=xr.DataArray(tstat2.pvalue, coords={'lat':('lat',pr_nino_grouped.coords['lat'].data),'lon':('lon',pr_nino_grouped.coords['lon'].data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval=0.1\n",
    "\n",
    "fig=plt.figure(figsize=(15,4))\n",
    "ax=fig.add_subplot(1,2,1,projection=ccrs.PlateCarree())\n",
    "ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "cbar_kwargs={'shrink':0.6}\n",
    "t.where(p<pval).plot(ax=ax,cbar_kwargs=cbar_kwargs)\n",
    "\n",
    "ax=fig.add_subplot(1,2,2,projection=ccrs.PlateCarree())\n",
    "ax.add_feature(cf.COASTLINE.with_scale(\"50m\"),lw=0.3)\n",
    "ax.add_feature(cf.BORDERS.with_scale(\"50m\"),lw=0.7)\n",
    "ax.add_feature(cf.STATES.with_scale(\"50m\"),lw=0.3)\n",
    "cbar_kwargs={'shrink':0.6}\n",
    "t2.where(p<pval).plot(ax=ax,cbar_kwargs=cbar_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare event seasons to neutral seasons as well as ltm clim to find significance, t test difference in means\n",
    "# look for the NOAA season enso anomaly maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pr_anom.where(nino_events==1).groupby(nino_events.time.dt.season)#.mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,group in test:\n",
    "    print(label, group.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sel(season='DJF').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn!\n",
    "\n",
    "### Choose one of three coding mini-projects below to complete on your own and prepare to share your findings\n",
    "\n",
    "\n",
    "**Option 1 (easiest):** \n",
    "\n",
    "&emsp;Hints:\n",
    "- \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Option 2 (moderate):** \n",
    "\n",
    "&emsp;Hints:\n",
    "- \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "**Option 3 (hardest):**\n",
    "\n",
    "&emsp;Hints:\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek at the answer figure for option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek at the answer figure for option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek at the answer figure for option 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create answer codes for these and put them in the repo. Direct learners to answers after the work-on-your-own session."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyworkshop",
   "language": "python",
   "name": "pyworkshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "affcdfbef34b243274bba1a77328c47db46b2eb84771471f779184b380d9e9a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
